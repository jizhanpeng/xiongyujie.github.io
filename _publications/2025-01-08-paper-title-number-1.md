---
title: "Understanding Before Reasoning: Enhancing Chain-of-Thought with Iterative Summarization Pre-Prompting"
collection: publications
category: manuscripts
permalink: /publication/2025-01-08-paper-title-number-1
excerpt: '<div style="text-align: justify;">This paper proposes the Iterative Summarization Pre-Prompting (ISP²) method, which enhances the complex reasoning capabilities of large language models by adaptively extracting candidate information, rating the reliability of information pairs, and performing iterative summarization. Experiments show that this method can significantly improve model performance. Additionally, the paper analyzes the summarization steps and error sources of ISP².</div>'
date: 2025-01-08
venue: 'arXiv'
paperurl: 'http://jizhanpeng.cn/xiongyujie.github.io/files/Understanding_Before_Reasoning_Enhancing_Chain-of-Thought_with_Iterative_Summarization_Pre-Prompting.pdf'
citation: '<br/><div style="text-align: justify;">Understanding Before Reasoning: Enhancing Chain-of-Thought with Iterative Summarization Pre-Prompting, D.-H. Zhu, Y.-J. Xiong*, J.-C. Zhang, X.-J. Xie, C.-M. Xia, arxiv preprint, arxiv:2501.04341 (2025)</div>'
---

<div style="text-align: justify;">Chain-of-Thought (CoT) Prompting is the dominant paradigm applied in Large Language Models (LLMs) to enhance their capacity for complex reasoning. It guides LLMs to demonstrate the problem-solving process through a chain of reasoning steps, rather than requiring LLMs to generate the final answer directly. Despite its success, CoT encounters difficulties when key information required for the reasoning process is either implicit or missing. It primarily stems from the fact that CoT emphasizes the stages of reasoning, while neglecting the critical task of gathering and extracting essential core information in the early stage. In this paper, we propose a pre-prompting methodology called Iterative Summarization Pre-Prompting (ISP2), which can effectively refine the reasoning ability ofLLMs when key information is not explicitly presented. First, entities and their corresponding descriptions are extracted to form potential key information pairs from the question. Next, we introduce the reliability rating to assess the reliability of these information pairs. Then, two information pairs with the lowest rankings through the reliability rating are merged into a new potential information description, which includes a new entity and its corresponding description. This process is applied iteratively to guide the generation of a unique information pair. Finally, the obtained key information pair, along with the original question, is fed into LLMs for reasoning, resulting in the final answer. Extensive experiments are conducted to validate the effectiveness of the proposed method. The results show that, compared to existing methods, our approach yields a 7.1% improvement in performance. In summary, unlike traditional prompting methods, ISP2 adopts an inductive approach with pre-prompting. It demonstrates good plug-and-play performance and can theoretically be applied to improve performance across all reasoning frameworks. The code is available at: https://github.com/zdhgreat/ISP-2.</div>
<br/>
